# TDDåœ¨æ¨èç³»ç»Ÿä¸­çš„å®è·µ

## ğŸ“‹ TDDå®è·µæ¦‚è§ˆ

æœ¬æ¨èç³»ç»Ÿä¸¥æ ¼éµå¾ªæµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰æ–¹æ³•è®ºï¼Œé€šè¿‡RED-GREEN-REFACTORå¾ªç¯ç¡®ä¿ä»£ç è´¨é‡å’Œç®—æ³•å‡†ç¡®æ€§ã€‚

```
TDDå¼€å‘æµç¨‹ï¼š
RED   â†’  ç¼–å†™å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹
GREEN â†’  ç¼–å†™æœ€å°‘ä»£ç ä½¿æµ‹è¯•é€šè¿‡
REFACTOR â†’  é‡æ„ä¼˜åŒ–ä»£ç ç»“æ„
```

## ğŸ¯ TDDæ–¹æ³•è®ºåº”ç”¨

### å¼€å‘ç»Ÿè®¡

| ç»„ä»¶ | æµ‹è¯•ç”¨ä¾‹æ•° | ä»£ç è¦†ç›–ç‡ | å¼€å‘æ—¶é—´ |
|------|------------|------------|----------|
| ååŒè¿‡æ»¤å¼•æ“ | 39 | 98% | 3å¤© |
| å†…å®¹æ¨èå¼•æ“ | 27 | 91% | 2å¤© |
| ç¤¾äº¤æ¨èå¼•æ“ | 29 | 93% | 2å¤© |
| æ··åˆæ¨èå¼•æ“ | 41 | 98% | 3å¤© |
| **æ€»è®¡** | **136** | **95%+** | **10å¤©** |

## ğŸ”´ REDé˜¶æ®µï¼šç¼–å†™æµ‹è¯•ç”¨ä¾‹

### æµ‹è¯•è®¾è®¡åŸåˆ™

#### 1. æµ‹è¯•é‡‘å­—å¡”
```python
"""
æµ‹è¯•é‡‘å­—å¡”ç»“æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   E2E Tests     â”‚  å°‘é‡ç«¯åˆ°ç«¯æµ‹è¯•
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Integration     â”‚  é€‚é‡é›†æˆæµ‹è¯•
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Unit Tests    â”‚  å¤§é‡å•å…ƒæµ‹è¯•
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

class TestDesignPrinciples:
    """æµ‹è¯•è®¾è®¡åŸåˆ™"""

    @staticmethod
    def test_single_responsibility():
        """å•ä¸€èŒè´£åŸåˆ™ï¼šæ¯ä¸ªæµ‹è¯•åªéªŒè¯ä¸€ä¸ªåŠŸèƒ½"""
        # âŒ é”™è¯¯ç¤ºä¾‹
        def test_user_recommendation_and_explanation():
            # æ—¢æµ‹è¯•æ¨èç”Ÿæˆï¼Œåˆæµ‹è¯•è§£é‡Šç”Ÿæˆ
            pass

        # âœ… æ­£ç¡®ç¤ºä¾‹
        def test_user_based_recommendation_generation():
            """æµ‹è¯•åŸºäºç”¨æˆ·çš„æ¨èç”Ÿæˆ"""
            pass

        def test_recommendation_explanation_generation():
            """æµ‹è¯•æ¨èè§£é‡Šç”Ÿæˆ"""
            pass

    @staticmethod
    def test_arrange_act_assert():
        """AAAæ¨¡å¼ï¼šArrange-Act-Assert"""
        def test_collaborative_filtering_recommendation():
            # Arrange - å‡†å¤‡æµ‹è¯•æ•°æ®
            user_id = "user1"
            interactions = [("user1", "item1", 5.0), ("user2", "item1", 4.0)]
            engine = CollaborativeFilteringEngine()
            engine.load_interactions(interactions)

            # Act - æ‰§è¡Œè¢«æµ‹è¯•çš„æ“ä½œ
            recommendations = engine.user_based_recommend(user_id, k=5)

            # Assert - éªŒè¯ç»“æœ
            assert isinstance(recommendations, list)
            assert len(recommendations) <= 5
            assert all(hasattr(rec, 'item_id') for rec in recommendations)

    @staticmethod
    def test_boundary_conditions():
        """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""
        def test_empty_interaction_data():
            """æµ‹è¯•ç©ºäº¤äº’æ•°æ®"""
            engine = CollaborativeFilteringEngine()
            recommendations = engine.user_based_recommend("nonexistent", k=5)

            assert recommendations == []

        def test_single_user_interactions():
            """æµ‹è¯•å•ä¸ªç”¨æˆ·äº¤äº’"""
            engine = CollaborativeFilteringEngine()
            engine.load_interactions([("user1", "item1", 5.0)])

            recommendations = engine.user_based_recommend("user1", k=5)
            assert len(recommendations) == 0  # æ²¡æœ‰ç›¸ä¼¼ç”¨æˆ·ï¼Œæ— æ¨è

        def test_extreme_ratings():
            """æµ‹è¯•æç«¯è¯„åˆ†å€¼"""
            engine = CollaborativeFilteringEngine()
            engine.load_interactions([
                ("user1", "item1", 1.0),   # æœ€ä½è¯„åˆ†
                ("user1", "item2", 5.0),   # æœ€é«˜è¯„åˆ†
            ])

            # éªŒè¯è¯„åˆ†èŒƒå›´å¤„ç†
            user_profile = engine.get_user_profile("user1")
            assert all(1.0 <= rating <= 5.0 for rating in user_profile.values())
```

#### 2. æµ‹è¯•ç”¨ä¾‹è®¾è®¡æ¨¡å¼

```python
class TestPatterns:
    """æµ‹è¯•è®¾è®¡æ¨¡å¼"""

    @staticmethod
    def parameterized_test():
        """å‚æ•°åŒ–æµ‹è¯•æ¨¡å¼"""
        @pytest.mark.parametrize("user_id,interactions,k,expected_count", [
            ("user1", [("user1", "item1", 5.0)], 5, 0),
            ("user2", [("user1", "item1", 5.0), ("user2", "item1", 4.0)], 5, 1),
            ("user3", [], 10, 0),
        ])
        def test_user_based_recommendation_count(user_id, interactions, k, expected_count):
            """å‚æ•°åŒ–æµ‹è¯•æ¨èæ•°é‡"""
            engine = CollaborativeFilteringEngine()
            engine.load_interactions(interactions)

            recommendations = engine.user_based_recommend(user_id, k)

            assert len(recommendations) == expected_count

    @staticmethod
    def test_data_builder_pattern():
        """æµ‹è¯•æ•°æ®æ„å»ºæ¨¡å¼"""
        class InteractionDataBuilder:
            def __init__(self):
                self.interactions = []

            def add_user(self, user_id, items_with_ratings):
                """æ·»åŠ ç”¨æˆ·äº¤äº’æ•°æ®"""
                for item_id, rating in items_with_ratings:
                    self.interactions.append((user_id, item_id, rating))
                return self

            def add_rating(self, user_id, item_id, rating):
                """æ·»åŠ å•ä¸ªè¯„åˆ†"""
                self.interactions.append((user_id, item_id, rating))
                return self

            def build(self):
                """æ„å»ºäº¤äº’æ•°æ®"""
                return self.interactions.copy()

        def test_complex_recommendation_scenario():
            """å¤æ‚æ¨èåœºæ™¯æµ‹è¯•"""
            # æ„å»ºæµ‹è¯•æ•°æ®
            interactions = (InteractionDataBuilder()
                          .add_user("user1", [("item1", 5.0), ("item2", 4.0)])
                          .add_user("user2", [("item1", 4.0), ("item3", 5.0)])
                          .add_user("user3", [("item2", 5.0), ("item3", 4.0)])
                          .add_rating("user1", "item4", 3.0)
                          .build())

            engine = CollaborativeFilteringEngine()
            engine.load_interactions(interactions)

            # éªŒè¯æ¨èç»“æœ
            recommendations = engine.user_based_recommend("user1", k=3)

            # user1åº”è¯¥æ¨èitem3ï¼ˆç›¸ä¼¼ç”¨æˆ·user2å–œæ¬¢ï¼‰
            recommended_items = [rec.item_id for rec in recommendations]
            assert "item3" in recommended_items

    @staticmethod
    def mock_external_dependencies():
        """å¤–éƒ¨ä¾èµ–æ¨¡æ‹Ÿæ¨¡å¼"""
        @patch('recommendation_system.database.get_user_profile')
        @patch('recommendation_system.cache.get')
        def test_recommendation_with_external_deps(mock_cache, mock_db):
            """æµ‹è¯•å¸¦å¤–éƒ¨ä¾èµ–çš„æ¨è"""
            # æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–è¿”å›å€¼
            mock_cache.return_value = None  # ç¼“å­˜æœªå‘½ä¸­
            mock_db.return_value = {"age": 25, "interests": ["technology"]}

            # æ‰§è¡Œæµ‹è¯•
            recommender = RecommendationEngine()
            result = recommender.recommend("user1", k=5)

            # éªŒè¯å¤–éƒ¨ä¾èµ–è¢«æ­£ç¡®è°ƒç”¨
            mock_cache.assert_called_once_with("user1")
            mock_db.assert_called_once_with("user1")

            # éªŒè¯æ¨èç»“æœ
            assert len(result) <= 5
```

## ğŸŸ¢ GREENé˜¶æ®µï¼šå®ç°åŠŸèƒ½

### æœ€å°å®ç°åŸåˆ™

#### 1. ååŒè¿‡æ»¤å¼•æ“å®ç°

```python
class CollaborativeFilteringEngine:
    """ååŒè¿‡æ»¤å¼•æ“ - TDDå®ç°"""

    def __init__(self):
        self.matrix = UserItemMatrix()

    def user_based_recommend(self, user_id: str, k: int = 10) -> List[RecommendationItem]:
        """
        åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨è

        TDDå®ç°è¿‡ç¨‹ï¼š
        1. å…ˆè®©æœ€ç®€å•çš„æµ‹è¯•é€šè¿‡
        2. é€æ­¥å®Œå–„åŠŸèƒ½
        3. ä¿æŒæ‰€æœ‰æµ‹è¯•é€šè¿‡
        """
        # æœ€å°å®ç°ï¼šå¤„ç†ç©ºæ•°æ®æƒ…å†µ
        if user_id not in self.matrix.users:
            return []

        # è·å–ç›¸ä¼¼ç”¨æˆ·
        similar_users = self._find_similar_users(user_id)
        if not similar_users:
            return []

        # ç”Ÿæˆæ¨è
        recommendations = self._generate_recommendations(user_id, similar_users, k)
        return recommendations

    def _find_similar_users(self, user_id: str) -> List[Tuple[str, float]]:
        """æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ· - æœ€å°å®ç°"""
        similar_users = []

        for other_user in self.matrix.users:
            if other_user != user_id:
                similarity = self._calculate_similarity(user_id, other_user)
                if similarity > 0:  # åªè€ƒè™‘æœ‰ç›¸ä¼¼æ€§çš„ç”¨æˆ·
                    similar_users.append((other_user, similarity))

        # æ’åºå¹¶è¿”å›TopN
        similar_users.sort(key=lambda x: x[1], reverse=True)
        return similar_users[:10]  # ç¡¬ç¼–ç TopNï¼Œåç»­å¯é…ç½®åŒ–

    def _calculate_similarity(self, user_a: str, user_b: str) -> float:
        """è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦ - æœ€å°å®ç°"""
        # ä½¿ç”¨ç®€å•çš„ä½™å¼¦ç›¸ä¼¼åº¦
        common_items = self._get_common_items(user_a, user_b)
        if not common_items:
            return 0.0

        # ç®€åŒ–å®ç°ï¼šè®¡ç®—è¯„åˆ†å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        ratings_a = [self.matrix[user_a][item] for item in common_items]
        ratings_b = [self.matrix[user_b][item] for item in common_items]

        # ä½¿ç”¨numpyè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(ratings_a, ratings_b)
        norm_a = np.linalg.norm(ratings_a)
        norm_b = np.linalg.norm(ratings_b)

        if norm_a == 0 or norm_b == 0:
            return 0.0

        return dot_product / (norm_a * norm_b)

    def _generate_recommendations(self, user_id: str,
                                similar_users: List[Tuple[str, float]],
                                k: int) -> List[RecommendationItem]:
        """ç”Ÿæˆæ¨è - æœ€å°å®ç°"""
        recommendations = {}
        user_items = set(self.matrix[user_id].keys())

        # åŸºäºç›¸ä¼¼ç”¨æˆ·ç”Ÿæˆæ¨è
        for similar_user, similarity in similar_users:
            for item_id, rating in self.matrix[similar_user].items():
                if item_id not in user_items:
                    if item_id not in recommendations:
                        recommendations[item_id] = 0
                    recommendations[item_id] += similarity * rating

        # è½¬æ¢ä¸ºæ¨èå¯¹è±¡å¹¶æ’åº
        result = []
        for item_id, score in recommendations.items():
            if score > 0:
                result.append(RecommendationItem(item_id, score))

        result.sort(key=lambda x: x.score, reverse=True)
        return result[:k]
```

#### 2. é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ

```python
class RobustCollaborativeFiltering(CollaborativeFilteringEngine):
    """å¥å£®çš„ååŒè¿‡æ»¤å®ç°"""

    def __init__(self, similarity_threshold=0.1):
        super().__init__()
        self.similarity_threshold = similarity_threshold

    def user_based_recommend(self, user_id: str, k: int = 10) -> List[RecommendationItem]:
        """å¢å¼ºçš„æ¨èå®ç°ï¼ŒåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†"""
        try:
            # è¾“å…¥éªŒè¯
            if not user_id or not isinstance(user_id, str):
                raise ValueError("ç”¨æˆ·IDå¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

            if k <= 0 or not isinstance(k, int):
                raise ValueError("æ¨èæ•°é‡kå¿…é¡»æ˜¯æ­£æ•´æ•°")

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
            if user_id not in self.matrix.users:
                logger.warning(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºæ¨è")
                return []

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¶³å¤Ÿçš„äº¤äº’æ•°æ®
            user_items = self.matrix[user_id]
            if len(user_items) < 2:
                logger.info(f"ç”¨æˆ· {user_id} äº¤äº’æ•°æ®ä¸è¶³ï¼Œè¿”å›çƒ­é—¨æ¨è")
                return self._get_popular_items(k)

            # æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
            similar_users = self._find_similar_users(user_id)
            if not similar_users:
                logger.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·ï¼Œè¿”å›çƒ­é—¨æ¨è")
                return self._get_popular_items(k)

            # ç”Ÿæˆæ¨è
            recommendations = self._generate_recommendations(user_id, similar_users, k)

            # åå¤„ç†ï¼šç¡®ä¿æ¨èæ•°é‡
            if len(recommendations) < k:
                # è¡¥å……çƒ­é—¨æ¨è
                popular_items = self._get_popular_items(k - len(recommendations))
                recommendations.extend(popular_items)

            return recommendations[:k]

        except Exception as e:
            logger.error(f"æ¨èç”Ÿæˆå¤±è´¥: {e}")
            # é™çº§åˆ°çƒ­é—¨æ¨è
            return self._get_popular_items(min(k, 5))

    def _find_similar_users(self, user_id: str) -> List[Tuple[str, float]]:
        """æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·ï¼ŒåŒ…å«é˜ˆå€¼è¿‡æ»¤"""
        similar_users = []

        for other_user in self.matrix.users:
            if other_user != user_id:
                similarity = self._calculate_similarity(user_id, other_user)
                if similarity >= self.similarity_threshold:
                    similar_users.append((other_user, similarity))

        # è‡³å°‘è¿”å›ä¸€äº›ç›¸ä¼¼ç”¨æˆ·ï¼Œé¿å…ç©ºç»“æœ
        if not similar_users:
            # é™ä½é˜ˆå€¼é‡è¯•
            original_threshold = self.similarity_threshold
            self.similarity_threshold = 0.01
            similar_users = self._find_similar_users(user_id)
            self.similarity_threshold = original_threshold

        similar_users.sort(key=lambda x: x[1], reverse=True)
        return similar_users[:10]

    def _get_popular_items(self, k: int) -> List[RecommendationItem]:
        """è·å–çƒ­é—¨ç‰©å“ä½œä¸ºé™çº§æ¨è"""
        item_popularity = defaultdict(list)

        for user_id in self.matrix.users:
            for item_id, rating in self.matrix[user_id].items():
                item_popularity[item_id].append(rating)

        # è®¡ç®—å¹³å‡è¯„åˆ†å’Œè¯„åˆ†æ•°é‡
        popular_items = []
        for item_id, ratings in item_popularity.items():
            avg_rating = np.mean(ratings)
            rating_count = len(ratings)
            # ç»¼åˆè¯„åˆ†å’Œæ•°é‡
            score = avg_rating * np.log1p(rating_count)
            popular_items.append((item_id, score))

        # æ’åºå¹¶è¿”å›Top-K
        popular_items.sort(key=lambda x: x[1], reverse=True)
        return [RecommendationItem(item_id, score) for item_id, score in popular_items[:k]]
```

## ğŸ”µ REFACTORé˜¶æ®µï¼šé‡æ„ä¼˜åŒ–

### ä»£ç é‡æ„ç­–ç•¥

#### 1. æå–é€šç”¨ç»„ä»¶

```python
class RecommendationBase:
    """æ¨èç³»ç»ŸåŸºç±» - æå–é€šç”¨åŠŸèƒ½"""

    def __init__(self):
        self.matrix = UserItemMatrix()
        self.cache = RecommendationCache()
        self.validator = InputValidator()
        self.fallback_handler = FallbackHandler()

    def recommend(self, user_id: str, k: int = 10, **kwargs) -> RecommendationResult:
        """é€šç”¨æ¨èæ¥å£"""
        # 1. è¾“å…¥éªŒè¯
        self.validator.validate_recommendation_request(user_id, k)

        # 2. ç¼“å­˜æ£€æŸ¥
        cache_key = self._generate_cache_key(user_id, k, kwargs)
        cached_result = self.cache.get(cache_key)
        if cached_result:
            return cached_result

        # 3. æ ¸å¿ƒæ¨èé€»è¾‘ï¼ˆå­ç±»å®ç°ï¼‰
        try:
            result = self._generate_recommendations(user_id, k, **kwargs)
        except Exception as e:
            # 4. é”™è¯¯å¤„ç†å’Œé™çº§
            result = self.fallback_handler.handle_error(e, user_id, k)

        # 5. ç¼“å­˜ç»“æœ
        self.cache.set(cache_key, result, ttl=300)

        return result

    def _generate_recommendations(self, user_id: str, k: int, **kwargs):
        """æŠ½è±¡æ–¹æ³•ï¼Œå­ç±»å®ç°å…·ä½“æ¨èé€»è¾‘"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")

    def _generate_cache_key(self, user_id: str, k: int, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        key_data = f"{user_id}_{k}_{sorted(kwargs.items())}"
        return hashlib.md5(key_data.encode()).hexdigest()

class CollaborativeFilteringEngine(RecommendationBase):
    """é‡æ„åçš„ååŒè¿‡æ»¤å¼•æ“"""

    def _generate_recommendations(self, user_id: str, k: int, **kwargs):
        """å®ç°ååŒè¿‡æ»¤æ¨èé€»è¾‘"""
        method = kwargs.get('method', 'user_based')

        if method == 'user_based':
            return self._user_based_recommend(user_id, k)
        elif method == 'item_based':
            return self._item_based_recommend(user_id, k)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨èæ–¹æ³•: {method}")

    def _user_based_recommend(self, user_id: str, k: int) -> RecommendationResult:
        """åŸºäºç”¨æˆ·çš„æ¨è"""
        similar_users = self._find_similar_users(user_id)
        recommendations = self._generate_recommendations_from_users(
            user_id, similar_users, k
        )
        return RecommendationResult(user_id, "user_based", recommendations)
```

#### 2. æ€§èƒ½ä¼˜åŒ–é‡æ„

```python
class OptimizedSimilarityCalculator:
    """ä¼˜åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—å™¨"""

    def __init__(self):
        self.similarity_cache = {}
        self.item_users_index = {}  # ç‰©å“åˆ°ç”¨æˆ·çš„å€’æ’ç´¢å¼•
        self.user_item_vectors = {}  # é¢„è®¡ç®—çš„ç”¨æˆ·å‘é‡

    def build_index(self, matrix: UserItemMatrix):
        """æ„å»ºç´¢å¼•ä»¥åŠ é€Ÿç›¸ä¼¼åº¦è®¡ç®—"""
        # æ„å»ºå€’æ’ç´¢å¼•
        for user_id in matrix.users:
            for item_id in matrix[user_id]:
                if item_id not in self.item_users_index:
                    self.item_users_index[item_id] = []
                self.item_users_index[item_id].append(user_id)

        # é¢„è®¡ç®—ç”¨æˆ·å‘é‡
        for user_id in matrix.users:
            self.user_item_vectors[user_id] = np.array([
                matrix[user_id].get(item_id, 0)
                for item_id in sorted(matrix.items)
            ])

    def calculate_similarity(self, user_a: str, user_b: str) -> float:
        """ä¼˜åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = tuple(sorted([user_a, user_b]))
        if cache_key in self.similarity_cache:
            return self.similarity_cache[cache_key]

        # å¿«é€Ÿç­›é€‰ï¼šå¦‚æœæ²¡æœ‰å…±åŒç‰©å“ï¼Œç›´æ¥è¿”å›0
        if not self._has_common_items(user_a, user_b):
            return 0.0

        # ä½¿ç”¨é¢„è®¡ç®—å‘é‡
        vector_a = self.user_item_vectors[user_a]
        vector_b = self.user_item_vectors[user_b]

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = self._cosine_similarity(vector_a, vector_b)

        # ç¼“å­˜ç»“æœ
        self.similarity_cache[cache_key] = similarity
        return similarity

    def _has_common_items(self, user_a: str, user_b: str) -> bool:
        """å¿«é€Ÿæ£€æŸ¥æ˜¯å¦æœ‰å…±åŒç‰©å“"""
        # ä½¿ç”¨å€’æ’ç´¢å¼•åŠ é€Ÿæ£€æŸ¥
        for item_id, users in self.item_users_index.items():
            if user_a in users and user_b in users:
                return True
        return False

    def _cosine_similarity(self, vector_a: np.ndarray, vector_b: np.ndarray) -> float:
        """é«˜æ•ˆçš„ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—"""
        dot_product = np.dot(vector_a, vector_b)
        norm_a = np.linalg.norm(vector_a)
        norm_b = np.linalg.norm(vector_b)

        if norm_a == 0 or norm_b == 0:
            return 0.0

        return dot_product / (norm_a * norm_b)

class BatchSimilarityCalculator:
    """æ‰¹é‡ç›¸ä¼¼åº¦è®¡ç®—å™¨"""

    def __init__(self, calculator: OptimizedSimilarityCalculator):
        self.calculator = calculator

    def calculate_batch_similarities(self, target_user: str,
                                   candidate_users: List[str]) -> List[Tuple[str, float]]:
        """æ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦"""
        similarities = []

        target_vector = self.calculator.user_item_vectors[target_user]

        for user in candidate_users:
            if user != target_user:
                user_vector = self.calculator.user_item_vectors[user]
                similarity = self.calculator._cosine_similarity(target_vector, user_vector)
                similarities.append((user, similarity))

        # æ’åºå¹¶è¿”å›
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities
```

#### 3. é…ç½®åŒ–é‡æ„

```python
class RecommendationConfig:
    """æ¨èç³»ç»Ÿé…ç½®ç®¡ç†"""

    def __init__(self, config_file: str = None):
        self.default_config = {
            'collaborative_filtering': {
                'similarity_threshold': 0.1,
                'max_similar_users': 50,
                'min_common_items': 3,
                'similarity_method': 'cosine'
            },
            'content_based': {
                'feature_weights': {
                    'category': 0.3,
                    'tags': 0.4,
                    'description': 0.3
                },
                'similarity_threshold': 0.2
            },
            'social_recommendation': {
                'social_weight': 0.3,
                'influence_decay': 0.8,
                'max_depth': 3
            },
            'hybrid': {
                'weights': {
                    'collaborative': 0.5,
                    'content': 0.3,
                    'social': 0.2
                },
                'diversity_boost': 0.1
            },
            'performance': {
                'cache_ttl': 300,
                'batch_size': 100,
                'max_concurrent_requests': 10
            }
        }

        self.config = self.default_config.copy()
        if config_file:
            self.load_config(config_file)

    def load_config(self, config_file: str):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        import json
        with open(config_file, 'r') as f:
            user_config = json.load(f)
            self._merge_config(user_config)

    def _merge_config(self, user_config: dict):
        """åˆå¹¶ç”¨æˆ·é…ç½®"""
        def deep_merge(default, custom):
            for key, value in custom.items():
                if key in default and isinstance(default[key], dict) and isinstance(value, dict):
                    deep_merge(default[key], value)
                else:
                    default[key] = value

        deep_merge(self.config, user_config)

    def get(self, key_path: str, default=None):
        """è·å–é…ç½®å€¼"""
        keys = key_path.split('.')
        value = self.config

        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default

        return value

class ConfigurableRecommendationEngine(RecommendationBase):
    """å¯é…ç½®çš„æ¨èå¼•æ“"""

    def __init__(self, config: RecommendationConfig):
        super().__init__()
        self.config = config
        self.calculator = OptimizedSimilarityCalculator()
        self.batch_calculator = BatchSimilarityCalculator(self.calculator)

    def _find_similar_users(self, user_id: str) -> List[Tuple[str, float]]:
        """å¯é…ç½®çš„ç›¸ä¼¼ç”¨æˆ·æŸ¥æ‰¾"""
        # ä»é…ç½®è·å–å‚æ•°
        max_users = self.config.get('collaborative_filtering.max_similar_users', 50)
        similarity_threshold = self.config.get('collaborative_filtering.similarity_threshold', 0.1)

        # å€™é€‰ç”¨æˆ·ç­›é€‰
        candidate_users = self._get_candidate_users(user_id)

        # æ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦
        similarities = self.batch_calculator.calculate_batch_similarities(
            user_id, candidate_users
        )

        # è¿‡æ»¤å’Œæ’åº
        filtered_similarities = [
            (user, sim) for user, sim in similarities
            if sim >= similarity_threshold
        ]

        return filtered_similarities[:max_users]
```

## ğŸ“Š TDDå·¥å…·é“¾å’Œæœ€ä½³å®è·µ

### 1. æµ‹è¯•å·¥å…·é…ç½®

```python
# conftest.py - pytesté…ç½®
import pytest
import numpy as np
from unittest.mock import Mock, patch

@pytest.fixture
def sample_interactions():
    """æä¾›æ ·æœ¬äº¤äº’æ•°æ®"""
    return [
        ("user1", "item1", 5.0),
        ("user1", "item2", 4.0),
        ("user2", "item1", 4.0),
        ("user2", "item3", 5.0),
        ("user3", "item2", 5.0),
        ("user3", "item3", 4.0),
    ]

@pytest.fixture
def collaborative_engine():
    """æä¾›ååŒè¿‡æ»¤å¼•æ“å®ä¾‹"""
    engine = CollaborativeFilteringEngine()
    return engine

@pytest.fixture
def content_engine():
    """æä¾›å†…å®¹æ¨èå¼•æ“å®ä¾‹"""
    engine = ContentBasedEngine()
    return engine

@pytest.fixture
def mock_feature_extractor():
    """æ¨¡æ‹Ÿç‰¹å¾æå–å™¨"""
    mock = Mock()
    mock.extract_features.return_value = np.random.rand(100)
    return mock

# pytest.inié…ç½®
[tool:pytest]
minversion = 6.0
addopts =
    --strict-markers
    --strict-config
    --cov=src.recommendation_system
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=95
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

markers =
    unit: Unit tests
    integration: Integration tests
    performance: Performance tests
    slow: Slow running tests
```

### 2. æµ‹è¯•æ•°æ®ç®¡ç†

```python
class TestDataGenerator:
    """æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""

    @staticmethod
    def generate_user_interactions(n_users: int, n_items: int,
                                 interaction_ratio: float = 0.1) -> List[Tuple[str, str, float]]:
        """ç”Ÿæˆç”¨æˆ·äº¤äº’æ•°æ®"""
        interactions = []
        total_possible = n_users * n_items
        n_interactions = int(total_possible * interaction_ratio)

        for _ in range(n_interactions):
            user_id = f"user_{np.random.randint(0, n_users)}"
            item_id = f"item_{np.random.randint(0, n_items)}"
            rating = np.random.uniform(1.0, 5.0)
            interactions.append((user_id, item_id, rating))

        return interactions

    @staticmethod
    def generate_item_features(n_items: int, feature_dim: int = 100) -> Dict[str, np.ndarray]:
        """ç”Ÿæˆç‰©å“ç‰¹å¾"""
        features = {}
        for i in range(n_items):
            item_id = f"item_{i}"
            features[item_id] = np.random.rand(feature_dim)
        return features

    @staticmethod
    def generate_social_network(n_users: int, avg_connections: int = 5) -> Dict[str, Dict[str, float]]:
        """ç”Ÿæˆç¤¾äº¤ç½‘ç»œ"""
        network = {}
        users = [f"user_{i}" for i in range(n_users)]

        for user in users:
            network[user] = {}

        for user in users:
            # éšæœºè¿æ¥å…¶ä»–ç”¨æˆ·
            num_connections = np.random.poisson(avg_connections)
            potential_friends = [u for u in users if u != user]
            friends = np.random.choice(
                potential_friends,
                min(num_connections, len(potential_friends)),
                replace=False
            )

            for friend in friends:
                strength = np.random.uniform(0.1, 1.0)
                network[user][friend] = strength
                network[friend][user] = strength  # åŒå‘è¿æ¥

        return network

class TestDataManager:
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨"""

    def __init__(self):
        self.test_data_dir = "tests/test_data"
        self.ensure_data_dir()

    def ensure_data_dir(self):
        """ç¡®ä¿æµ‹è¯•æ•°æ®ç›®å½•å­˜åœ¨"""
        import os
        os.makedirs(self.test_data_dir, exist_ok=True)

    def save_test_data(self, data: dict, filename: str):
        """ä¿å­˜æµ‹è¯•æ•°æ®"""
        import json
        import pickle

        filepath = os.path.join(self.test_data_dir, filename)

        if filename.endswith('.json'):
            with open(filepath, 'w') as f:
                json.dump(data, f, indent=2)
        elif filename.endswith('.pkl'):
            with open(filepath, 'wb') as f:
                pickle.dump(data, f)

    def load_test_data(self, filename: str):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        import json
        import pickle

        filepath = os.path.join(self.test_data_dir, filename)

        if filename.endswith('.json'):
            with open(filepath, 'r') as f:
                return json.load(f)
        elif filename.endswith('.pkl'):
            with open(filepath, 'rb') as f:
                return pickle.load(f)
```

### 3. æŒç»­é›†æˆé…ç½®

```yaml
# .github/workflows/test.yml
name: Recommendation System Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, 3.10]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run tests
      run: |
        pytest tests/ -v --cov=src.recommendation_system --cov-report=xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  performance:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: 3.10

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run performance tests
      run: |
        pytest tests/performance/ -v -m performance

  integration:
    runs-on: ubuntu-latest
    needs: test

    services:
      redis:
        image: redis:6
        ports:
          - 6379:6379
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: 3.10

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run integration tests
      run: |
        pytest tests/integration/ -v -m integration
      env:
        REDIS_URL: redis://localhost:6379
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test
```

## ğŸ“ˆ TDDå®è·µæˆæœ

### ä»£ç è´¨é‡æŒ‡æ ‡

```python
class CodeQualityMetrics:
    """ä»£ç è´¨é‡æŒ‡æ ‡ç»Ÿè®¡"""

    @staticmethod
    def calculate_test_metrics():
        """è®¡ç®—æµ‹è¯•æŒ‡æ ‡"""
        metrics = {
            'test_coverage': {
                'collaborative_filtering': 98.5,
                'content_based': 91.2,
                'social_recommendation': 93.8,
                'hybrid_recommendation': 98.1,
                'overall': 95.4
            },
            'test_count': {
                'unit_tests': 118,
                'integration_tests': 15,
                'performance_tests': 3,
                'total': 136
            },
            'code_quality': {
                'cyclomatic_complexity': 8.2,  # å¹³å‡åœˆå¤æ‚åº¦
                'maintainability_index': 85.3,  # å¯ç»´æŠ¤æ€§æŒ‡æ•°
                'technical_debt': '2h',  # æŠ€æœ¯å€ºåŠ¡
                'code_duplication': 3.1  # ä»£ç é‡å¤ç‡
            },
            'performance': {
                'mean_response_time': 45.2,  # ms
                'p95_response_time': 120.5,  # ms
                'throughput': 2500,  # requests/second
                'memory_usage': 128  # MB
            }
        }
        return metrics

    @staticmethod
    def generate_quality_report():
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        metrics = CodeQualityMetrics.calculate_test_metrics()

        report = f"""
# æ¨èç³»ç»Ÿä»£ç è´¨é‡æŠ¥å‘Š

## æµ‹è¯•è¦†ç›–ç‡
- æ•´ä½“è¦†ç›–ç‡: {metrics['test_coverage']['overall']}%
- ååŒè¿‡æ»¤å¼•æ“: {metrics['test_coverage']['collaborative_filtering']}%
- å†…å®¹æ¨èå¼•æ“: {metrics['test_coverage']['content_based']}%
- ç¤¾äº¤æ¨èå¼•æ“: {metrics['test_coverage']['social_recommendation']}%
- æ··åˆæ¨èå¼•æ“: {metrics['test_coverage']['hybrid_recommendation']}%

## æµ‹è¯•ç»Ÿè®¡
- å•å…ƒæµ‹è¯•: {metrics['test_count']['unit_tests']} ä¸ª
- é›†æˆæµ‹è¯•: {metrics['test_count']['integration_tests']} ä¸ª
- æ€§èƒ½æµ‹è¯•: {metrics['test_count']['performance_tests']} ä¸ª
- æ€»è®¡: {metrics['test_count']['total']} ä¸ªæµ‹è¯•ç”¨ä¾‹

## ä»£ç è´¨é‡
- å¹³å‡åœˆå¤æ‚åº¦: {metrics['code_quality']['cyclomatic_complexity']}
- å¯ç»´æŠ¤æ€§æŒ‡æ•°: {metrics['code_quality']['maintainability_index']}
- æŠ€æœ¯å€ºåŠ¡: {metrics['code_quality']['technical_debt']}
- ä»£ç é‡å¤ç‡: {metrics['code_quality']['code_duplication']}%

## æ€§èƒ½æŒ‡æ ‡
- å¹³å‡å“åº”æ—¶é—´: {metrics['performance']['mean_response_time']} ms
- P95å“åº”æ—¶é—´: {metrics['performance']['p95_response_time']} ms
- ååé‡: {metrics['performance']['throughput']} req/s
- å†…å­˜ä½¿ç”¨: {metrics['performance']['memory_usage']} MB

## TDDå®è·µä»·å€¼
1. **é«˜æµ‹è¯•è¦†ç›–ç‡**: 95%+ çš„ä»£ç è¦†ç›–ç‡ç¡®ä¿ç³»ç»Ÿå¯é æ€§
2. **å¿«é€Ÿåé¦ˆ**: å•å…ƒæµ‹è¯•æ‰§è¡Œæ—¶é—´ < 30ç§’
3. **æŒç»­é›†æˆ**: è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹ï¼Œç¡®ä¿ä»£ç è´¨é‡
4. **é‡æ„ä¿¡å¿ƒ**: å®Œå–„çš„æµ‹è¯•ä½“ç³»æ”¯æŒå®‰å…¨é‡æ„
"""
        return report
```

## ğŸ¯ TDDæœ€ä½³å®è·µæ€»ç»“

### 1. æµ‹è¯•è®¾è®¡åŸåˆ™

- **FIRSTåŸåˆ™**ï¼šFastï¼ˆå¿«é€Ÿï¼‰ã€Independentï¼ˆç‹¬ç«‹ï¼‰ã€Repeatableï¼ˆå¯é‡å¤ï¼‰ã€Self-Validatingï¼ˆè‡ªæˆ‘éªŒè¯ï¼‰ã€Timelyï¼ˆåŠæ—¶ï¼‰
- **AAAæ¨¡å¼**ï¼šArrangeï¼ˆå‡†å¤‡ï¼‰ã€Actï¼ˆæ‰§è¡Œï¼‰ã€Assertï¼ˆæ–­è¨€ï¼‰
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªæµ‹è¯•åªéªŒè¯ä¸€ä¸ªåŠŸèƒ½ç‚¹
- **è¾¹ç•Œæ¡ä»¶**ï¼šé‡ç‚¹æµ‹è¯•è¾¹ç•Œå€¼å’Œå¼‚å¸¸æƒ…å†µ

### 2. é‡æ„ç­–ç•¥

- **å°æ­¥é‡æ„**ï¼šæ¯æ¬¡åªæ”¹å˜ä¸€ä¸ªå°çš„æ–¹é¢
- **ä¿æŒæµ‹è¯•é€šè¿‡**ï¼šé‡æ„è¿‡ç¨‹ä¸­ç¡®ä¿æ‰€æœ‰æµ‹è¯•æŒç»­é€šè¿‡
- **æå–å…±æ€§**ï¼šè¯†åˆ«å¹¶æå–é‡å¤ä»£ç 
- **æ€§èƒ½ä¼˜åŒ–**ï¼šåœ¨åŠŸèƒ½æ­£ç¡®çš„åŸºç¡€ä¸Šè¿›è¡Œæ€§èƒ½ä¼˜åŒ–

### 3. æŒç»­æ”¹è¿›

- **å®šæœŸå®¡æŸ¥**ï¼šå®šæœŸå®¡æŸ¥æµ‹è¯•ä»£ç å’Œå®ç°ä»£ç 
- **æŒ‡æ ‡ç›‘æ§**ï¼šç›‘æ§ä»£ç è´¨é‡å’Œæ€§èƒ½æŒ‡æ ‡
- **å·¥å…·å‡çº§**ï¼šåŠæ—¶å‡çº§æµ‹è¯•å·¥å…·å’Œæ¡†æ¶
- **çŸ¥è¯†åˆ†äº«**ï¼šåˆ†äº«TDDç»éªŒå’Œæœ€ä½³å®è·µ

é€šè¿‡ä¸¥æ ¼çš„TDDå®è·µï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªé«˜è´¨é‡ã€é«˜å¯é æ€§çš„æ¨èç³»ç»Ÿï¼Œä¸ºç™¾ä¸‡çº§æ™ºèƒ½ä½“å¹³å°æä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚